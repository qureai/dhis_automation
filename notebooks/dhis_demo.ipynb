{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DHIS Medical Image Processing - Django Integration Demo\n",
    "\n",
    "This notebook demonstrates how to interact with the Django backend for the DHIS medical image processing system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Django Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import django\n",
    "\n",
    "# Add the backend directory to the Python path\n",
    "sys.path.insert(0, '/app')\n",
    "\n",
    "# Configure Django settings\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'image_processor.settings')\n",
    "django.setup()\n",
    "\n",
    "print(\"Django version:\", django.get_version())\n",
    "print(\"Django setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Django Models and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.models import ImageUpload\n",
    "from api.utils import LLMService\n",
    "from django.conf import settings\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"Models and utilities imported successfully!\")\n",
    "print(f\"\\nDatabase: {settings.DATABASES['default']['ENGINE']}\")\n",
    "print(f\"Media Root: {settings.MEDIA_ROOT}\")\n",
    "print(f\"Portkey Model: {settings.PORTKEY_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Existing Image Uploads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image uploads\n",
    "uploads = ImageUpload.objects.all()\n",
    "print(f\"Total uploads: {uploads.count()}\")\n",
    "\n",
    "# Display recent uploads\n",
    "if uploads.exists():\n",
    "    recent_uploads = uploads.order_by('-uploaded_at')[:5]\n",
    "    \n",
    "    data = []\n",
    "    for upload in recent_uploads:\n",
    "        data.append({\n",
    "            'ID': upload.id,\n",
    "            'Filename': upload.original_filename,\n",
    "            'Status': upload.processing_status,\n",
    "            'Uploaded': upload.uploaded_at.strftime('%Y-%m-%d %H:%M'),\n",
    "            'Has Results': bool(upload.extracted_data)\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"\\nRecent Uploads:\")\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"No uploads found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Extracted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze extracted medical data\n",
    "processed_uploads = ImageUpload.objects.filter(processing_status='completed')\n",
    "\n",
    "if processed_uploads.exists():\n",
    "    extracted_data_list = []\n",
    "    \n",
    "    for upload in processed_uploads:\n",
    "        if upload.extracted_data:\n",
    "            try:\n",
    "                data = json.loads(upload.extracted_data) if isinstance(upload.extracted_data, str) else upload.extracted_data\n",
    "                data['upload_id'] = upload.id\n",
    "                data['filename'] = upload.original_filename\n",
    "                extracted_data_list.append(data)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    \n",
    "    if extracted_data_list:\n",
    "        df_extracted = pd.DataFrame(extracted_data_list)\n",
    "        print(\"Extracted Medical Information:\")\n",
    "        display(df_extracted[['upload_id', 'filename', 'first_name', 'last_name', 'date_of_birth', 'date_of_diagnosis']].head())\n",
    "        \n",
    "        # Case detection options analysis\n",
    "        if 'case_detection_options' in df_extracted.columns:\n",
    "            all_options = []\n",
    "            for options in df_extracted['case_detection_options'].dropna():\n",
    "                if isinstance(options, list):\n",
    "                    all_options.extend(options)\n",
    "            \n",
    "            if all_options:\n",
    "                print(\"\\nCase Detection Options Summary:\")\n",
    "                option_counts = pd.Series(all_options).value_counts()\n",
    "                display(option_counts)\n",
    "    else:\n",
    "        print(\"No extracted data found.\")\n",
    "else:\n",
    "    print(\"No processed uploads found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test LLM Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM service\n",
    "llm_service = LLMService()\n",
    "\n",
    "# Test with a sample medical text\n",
    "sample_text = \"\"\"\n",
    "Patient: John Doe\n",
    "Date of Birth: 15/03/1985\n",
    "Diagnosis Date: 10/01/2024\n",
    "Condition: Hypertension\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testing LLM extraction with sample text...\")\n",
    "print(\"Sample text:\")\n",
    "print(sample_text)\n",
    "\n",
    "try:\n",
    "    # Extract information using LLM\n",
    "    result = llm_service.extract_medical_info_from_text(sample_text)\n",
    "    print(\"\\nExtracted Information:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"Error testing LLM: {e}\")\n",
    "    print(\"Make sure Portkey API keys are configured in .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Database Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.db.models import Count, Q\n",
    "from django.utils import timezone\n",
    "\n",
    "# Get upload statistics\n",
    "stats = ImageUpload.objects.aggregate(\n",
    "    total=Count('id'),\n",
    "    pending=Count('id', filter=Q(processing_status='pending')),\n",
    "    processing=Count('id', filter=Q(processing_status='processing')),\n",
    "    completed=Count('id', filter=Q(processing_status='completed')),\n",
    "    failed=Count('id', filter=Q(processing_status='failed'))\n",
    ")\n",
    "\n",
    "print(\"Upload Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key.capitalize()}: {value}\")\n",
    "\n",
    "# Recent activity (last 7 days)\n",
    "seven_days_ago = timezone.now() - timedelta(days=7)\n",
    "recent_count = ImageUpload.objects.filter(uploaded_at__gte=seven_days_ago).count()\n",
    "print(f\"\\nUploads in last 7 days: {recent_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create a Test Upload (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to create a test upload\n",
    "# from django.core.files.base import ContentFile\n",
    "# import base64\n",
    "\n",
    "# # Create a test image upload\n",
    "# test_upload = ImageUpload(\n",
    "#     original_filename=\"test_medical_report.jpg\",\n",
    "#     processing_status=\"pending\"\n",
    "# )\n",
    "# \n",
    "# # Create a dummy file (1x1 white pixel PNG)\n",
    "# dummy_image = base64.b64decode(\"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg==\")\n",
    "# test_upload.image.save(\"test.png\", ContentFile(dummy_image), save=True)\n",
    "# \n",
    "# print(f\"Created test upload with ID: {test_upload.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all uploads to CSV\n",
    "if ImageUpload.objects.exists():\n",
    "    exports = []\n",
    "    for upload in ImageUpload.objects.all():\n",
    "        row = {\n",
    "            'id': upload.id,\n",
    "            'filename': upload.original_filename,\n",
    "            'status': upload.processing_status,\n",
    "            'uploaded_at': upload.uploaded_at.isoformat(),\n",
    "            'processed_at': upload.processed_at.isoformat() if upload.processed_at else None,\n",
    "        }\n",
    "        \n",
    "        # Add extracted data if available\n",
    "        if upload.extracted_data:\n",
    "            try:\n",
    "                data = json.loads(upload.extracted_data) if isinstance(upload.extracted_data, str) else upload.extracted_data\n",
    "                row.update(data)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        exports.append(row)\n",
    "    \n",
    "    df_export = pd.DataFrame(exports)\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = '/app/notebooks/dhis_exports.csv'\n",
    "    df_export.to_csv(csv_path, index=False)\n",
    "    print(f\"Data exported to: {csv_path}\")\n",
    "    print(f\"Total records: {len(df_export)}\")\n",
    "else:\n",
    "    print(\"No data to export.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}